{
    "batch_size" : 64,
    "gradient_accumulation_steps": 8,
    "mode":"wei",
    "dim" : 1024,
    "n_layers" : 16,
    "max_seq_len" : 1024,
    "n_heads" : 6,
    "vocab_size": 32000,
    "multiple_of" : 32, 
    "dropout": 0.0,
    "fsdp": false,
    "lr" : 5e-4
}
