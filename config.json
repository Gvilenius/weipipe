{
    "batch_size": 2,
    "gradient_accumulation_steps": 2,
    "mode": "wei",
    "dim": 1024,
    "n_layers": 1,
    "max_seq_len": 1024,
    "n_heads": 32,
    "vocab_size": 32000,
    "multiple_of": 32,
    "dropout": 0.0,
    "lr": 0.0005,
    "iters_num": 2,
    "output": true,
    "train_embedding": false,
    "checkpointing": true
}
