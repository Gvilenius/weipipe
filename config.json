{
    "batch_size": 1,
    "gradient_accumulation_steps": 8,
    "mode": "wei",
    "dim": 1024,
    "n_layers": 3,
    "max_seq_len": 2048,
    "n_heads": 32,
    "vocab_size": 32000,
    "multiple_of": 32,
    "dropout": 0.0,
    "lr": 0.0005,
    "iters_num": 2,
    "output": true,
    "train_embedding": true,
    "checkpointing":true
}
